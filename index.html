<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">

    <title>Taskflow</title>
    
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <link rel="stylesheet" href="css/reveal.css">
    <link rel="stylesheet" href="css/theme/black.css" id="theme">
    
    <!-- Theme used for syntax highlighting of code -->
    <link rel="stylesheet" href="lib/css/zenburn.css">
    
    <script src="https://use.fontawesome.com/539f0980a5.js"></script>
    
    <!-- vis.js graph drawing -->
    <link href="css/vis.min.css" rel="stylesheet" type="text/css"/>
    <script src="js/vis.min.js"></script>
  
  <script type="text/javascript"> 
 function submit() {
   var content = document.getElementById('code_area').innerText;
   document.getElementById('flow_graph').style.display = "none";
   var xhr = new XMLHttpRequest();
   xhr.onreadystatechange = function () {
     // readyState = 4 means the post operation is complete.
     if (xhr.readyState === 4) {
       // extract the image in response sent by backend
       var uInt8Array = new Uint8Array(this.response);
       var i = uInt8Array.length;
       var binaryString = new Array(i);
       while (i--) {
         binaryString[i] = String.fromCharCode(uInt8Array[i]);
       }
       var data = binaryString.join('');
       var base64 = window.btoa(data);
       document.getElementById('flow_graph').class = "animate-bottom";
       document.getElementById('flow_graph').style = "border: 0px; background:none";
       // Replace the old image by new image
       document.getElementById("flow_graph").src="data:image/png;base64,"+base64;
     }
   }
   // Send a post request to backend
   xhr.open('post', 'http://localhost:3000', true);
   xhr.responseType = 'arraybuffer';
   xhr.setRequestHeader('Content-Type', 'text/plain');
   xhr.send(content);
 }
</script>
    
    <!-- customized css -->
    <link rel="stylesheet" href="css/custom.css">
  </head>

  <body>

    <div class="reveal">
      <div class="slides">

        <section>
          <h1>Taskflow</h1>
          <h3>Modern C++ Parallel Task Programming</h3>
          <p><i class="fa fa-github"></i><a href="https://github.com/taskflow/taskflow">Project GitHub</a></p>
          <p><i class="fa fa-book"></i><a href="https://taskflow.github.io/taskflow/index.html">API Documentation</a></p>
          <p><small>Presented by <a href="https://tsung-wei-huang.github.io/">Tsung-Wei Huang</a></small></p>
        </section>
        
<section>
  <p>How can we make it easier for C++ developers to quickly write efficient parallel programs?</p>
</section>

<section>
  <h2>Want Parallel Code</h2>
  <ul>
    <li>Simple</li>
    <li>Expressive</li>
    <li>Transparent</li>
    <li>Performant</li>
    <li>Productive</li>
  </ul>
</section>

<section>
  <h2>It's NOT Easy Though ...</h2>
  <ol>
    <li>Task Dependencies</li>
    <li>Data Race</li>
    <li>Concurrency Controls</li>
    <li>Thread Contention</li>
    <li>Debugging</li>
    <li>...</li>
  </ol>
</section>


<section>
<h2>A Homegrown Example</h2>
<img data-src="image/kitchen_flow.png", style="max-width: 400px">
</section>


<section>
<h2>C++ Thread</h2>
<pre><code class="language-cpp stretch" contenteditable=true>std::atomic_int garnish_ready{0}; // dependency variable
std::atomic_int meat_ready{0};    // dependency variable
std::atomic_int plating_ready{0}; // dependency variable
std::thread cook1 ([&] () { 
  garnish = cook_garnish(); garnish_ready = 1; 
});
std::thread cook2 ([&] () { 
  meat = cook_meat(); meat_ready = 1; 
});
std::thread chief ([&] () {
  while(!garnish_ready && !meat_ready);    // spinning
  plates = plating(garnish, meat); plating_ready = 1;
}); 
std::thread waiter1 ([&] () {
  while(!plating_ready); serve(plates[0]); // spinning
});
std::thread waiter2 ([&] () {
  while(!plating_ready); serve(plates[1]); // spinning
});
</code></pre>
<span class="fragment current-only" data-code-focus="4,7,10,14,17"></span>
<span class="fragment current-only" data-code-focus="1,2,3"></span>
<span class="fragment current-only" data-code-focus="11,15,18"></span>
</section>

<section>
<h2>OpenMP</h2>
<pre><code class="language-cpp stretch" contenteditable=true>#pragma omp parallel 
{
  #pragma omp single 
  {
    int c1c, c2c, cw1, cw2;
    #pragma omp task depend(out:c1c)
    garnish = cook_garnish();
    #pragma omp task depend(out:c2c)
    meat = cook_meat();
    #pragma omp task depend(in:c1c,c2c) depend(out:cw1,cw2)
    plates = plating(garnish, meat);
    #pragma omp task depend(in:cw1)
    serve(plates[0]);
    #pragma omp task depend(in:cw2)
    serve(plates[1]);
  }
}
</code></pre>
<span class="fragment current-only" data-code-focus="1,17"></span>
<span class="fragment current-only" data-code-focus="3,16"></span>
<span class="fragment current-only" data-code-focus="5"></span>
<span class="fragment current-only" data-code-focus="6,8,10,12,14"></span>
</section>

<section>
<h2>Intel TBB</h2>
<pre><code class="language-cpp stretch" contenteditable=true>using namespace tbb::flow;
task_scheduler_init init(default_num_threads());
graph g;

continue_node&lt;continue_msg&gt; cook1(g, [&amp;] (auto) { garnish = cook_garnish(); });
continue_node&lt;continue_msg&gt; cook2(g, [&amp;] (auto) { meat = cook_meat(); });
continue_node&lt;continue_msg&gt; chief(g, [&amp;] (auto) { plates = plating(garnish, meat); });
continue_node&lt;continue_msg&gt; waiter1(g, [&amp;] (auto) { serve(plates[0]); });
continue_node&lt;continue_msg&gt; waiter2(g, [&amp;] (auto) { serve(plates[1]); });
make_edge(cook1, chief); 
make_edge(cook2, chief); 
make_edge(chief, waiter1);
make_edge(chief, waiter2);

cook1.try_put(continue_msg());    // start at cook1
cook2.try_put(continue_msg());    // start at cook2
g.wait_for_all();
</code></pre>
<span class="fragment current-only" data-code-focus="5,6,7,8,9"></span>
<span class="fragment current-only" data-code-focus="10,11,12,13"></span>
<span class="fragment current-only" data-code-focus="15,16"></span>
<span class="fragment current-only" data-code-focus="17"></span>
</section>

<section>
<h2>Taskflow</h2>
<pre><code class="language-cpp stretch" contenteditable=true>tf::Taskflow executor;
tf::Taskflow taskflow;

auto [cook1, cook2, chief, waiter1, waiter2] = 
  taskflow.emplace(
  [&amp;] () { garnish = cook_garnish();         },
  [&amp;] () { meat    = cook_meat();            },
  [&amp;] () { plates  = plating(garnish, meat); },
  [&amp;] () { serve(plates[0]);                 },
  [&amp;] () { serve(plates[1]);                 }
);

cook1.precede(chief);        // cook1 runs before chief
cook2.precede(chief);        // cook2 runs before chief
chief.precede(waiter1);      // chief runs before waiter1
chief.precede(waiter2);      // chief runs before waiter2

executor.run(tf);
</code></pre>
<span class="fragment current-only" data-code-focus="2"></span>
<span class="fragment current-only" data-code-focus="4-11"></span>
<span class="fragment current-only" data-code-focus="13-16"></span>
<span class="fragment current-only" data-code-focus="18"></span>
</section>





<section>
<h2>Taskflow is FREE</h2>
<ul>
  <li>from explicit thread management</li>
  <li>from difficult lock mechanism</li>
  <li>from daunting class declaration</li>
</ul>
</section>
        
<section>
<h2>Development Cost</h2>
<small>SLOCCount Report</small>
<canvas class="stretch" data-chart="bar">
<!--
{
  "data" : {
    "labels": ["C++ Thread", "OpenMP", "Intel TBB", "Taskflow"],
    "datasets": [{
      "label": "$USD (left y-axis)",
      "yAxisID": "y-axis-0",
      "data": [538, 444, 585, 283]
    },{
      "label": "Lines of Code (right y-axis)",
      "yAxisID": "y-axis-1",
      "data": [24, 20, 26, 13]
    }]
  },
  "options": {
    "title": {
      "display": false,
      "text": "SLOCCount Report"
    },
    "tooltips": {"mode": "label"},
    "responsive": true,
    "scales": {
      "xAxes": [{
        "stacked": false
      }],
      "yAxes": [{
        "position": "left",
        "id": "y-axis-0"
      },{
        "position": "right",
        "id": "y-axis-1"
      }]
    }
  }
}
-->
</canvas>
</section>

<section>
<h2>What about Performance?</h2>
</section>

<section>
  <h2>Graph Algorithm</h2>
  <small>Runtime Comparison between OpenMP, Intel TBB, and Taskflow</small>
  <canvas data-chart="line" class="stretch">
<!--
{
 "data": {
  "labels": [2,3287,12987,28768,50973,79683,114367,155455,202419,255888,316493,382928,454704,534483,619460,711298],
  "datasets":[
   {
    "data":[0.896,1.4388,0.872,1.8276,3.3546,4.7556,6.6698,9.3192,11.9644,15.176,18.9224,23.8458,27.312,32.816,38.247,43.4582],
    "label":"Taskflow",
    "borderColor":"cyan",
    "fill": "false"
   },
   {
    "data":[0.0374,1.317,4.2774,9.321,16.9746,25.9622,38.0312,50.3518,64.6332,82.7606,102.973,123.687,149.113,173.564,199.442,230.201],
    "label":"OpenMP",
    "borderColor":"lime",
    "fill": "false"
   },
   {
    "data":[0.2212,0.4682,1.7642,3.8148,6.548,10.9376,15.6766,21.4428,27.5834,35.0644,43.0554,52.0932,61.858,72.6192,83.7176,96.5104],
    "label":"Intel TBB",
    "borderColor":"orange",
    "fill": "false"
   }
  ]
 },
 "options": { 
   "responsive" : "true",
   "scales": {
     "xAxes": [{
       "scaleLabel" : { "display":"true", "labelString": "graph size (|V| + |E| = # tasks)" }
     }],
     "yAxes": [{
       "scaleLabel" : { "display":"true", "labelString": "runtime (ms)" }
     }]
   }
 }
}
-->
</canvas>
</section>


<section>
  <h2>Matrix Operation</h2>
  <small>Runtime Comparison between OpenMP, Intel TBB, and Taskflow</small>
  <canvas data-chart="line" class="stretch">
<!--
{
 "data": {
  "labels": [16,1296,4624,10000,17424,26896,38416,51984,67600,85264,104976,126736,150544,176400,204304,234256,250000],
  "datasets":[
   {
    "data":[1.9486,0.8256,1.0208,1.865,2.823,4.5788,6.949,9.7488,13.0142,16.6228,19.8972,24.0684,28.415,33.5568,39.9492,44.4578,48.3986],
    "label":"Taskflow",
    "borderColor":"cyan",
    "fill": "false"
   },
   {
    "data":[1.1626,1.5816,4.6282,9.73,16.0318,24.5604,34.532,48.3302,60.3276,75.392,93.6938,113.024,135.142,155.222,180.36,212.705,228.124],
    "label":"OpenMP",
    "borderColor":"lime",
    "fill": "false"
   },
   {
    "data":[0.4102,0.7368,2.3828,4.5974,7.5568,11.3946,16.3492,22.0412,28.5956,35.4474,43.104,52.4276,61.6788,72.2758,83.8262,95.637,102.466],
    "label":"Intel TBB",
    "borderColor":"orange",
    "fill": "false"
   }
  ]
 },
 "options": { 
   "responsive" : "true",
   "scales": {
     "xAxes": [{
       "scaleLabel" : { "display":"true", "labelString": "partition count (# tasks)" }
     }],
     "yAxes": [{
       "scaleLabel" : { "display":"true", "labelString": "runtime (ms)" }
     }]
   }
 }
}
-->
</canvas>
</section>

<section>
  <h2>Real Gain is Tremendous</h2>
</section>

<section>
<h2>VLSI Timing Analysis</h2>
<small>Dev Cost between <a href="https://github.come/OpenTimer/">OpenTimer</a> v1 (OpenMP) and v2 (Taskflow)</small>
<canvas class="stretch" data-chart="bar">
<!--
{
  "data" : {
    "labels": ["v1 (OpenMP)", "v2 (Taskflow)"],
    "datasets": [{
      "label": "$USD (left y-axis)",
      "yAxisID": "y-axis-0",
      "data": [235000, 130000]
    },{
      "label": "Lines of Code (right y-axis)",
      "yAxisID": "y-axis-1",
      "data": [9123, 4482]
    }]
  },
  "options": {
    "tooltips": {"mode": "label"},
    "responsive": true,
    "scales": {
      "xAxes": [{
        "stacked": false
      }],
      "yAxes": [{
        "position": "left",
        "id": "y-axis-0"
      },{
        "position": "right",
        "id": "y-axis-1"
      }]
    }
  }
}
-->
</canvas>
</section>

<section>
  <h2>Runtime Performance</h2>
  <small>OpenTimer v1 (OpenMP) and v2 (Taskflow) </small>
  <canvas data-chart="line" class="stretch">
<!--
{
 "data": {
  "labels": [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],
  "datasets":[
   {
    "data":[1292,1335,1369,1525,1320,1346,1366,1391,1448,1393,1259,1192,1238,1220,1471,1404,1419,1220,1225,1245],
    "label":"v2 (Taskflow)",
    "borderColor":"cyan",
    "fill": "false"
   },
   {
    "data":[2853,2957,3058,3032,3007,3052,2925,2898,2822,2854,2757,2963,2832,2834,2716,2777,2538,2612,2592,3176],
    "label":"v1 (OpenMP)",
    "borderColor":"lime",
    "fill": "false"
   }
  ]
 },
 "options": { 
   "responsive" : "true",
   "scales": {
     "xAxes": [{
       "scaleLabel" : { "display":"true", "labelString": "incremental timing iteration" }
     }],
     "yAxes": [{
       "scaleLabel" : { "display":"true", "labelString": "runtime (ms)" }
     }]
   }
 }
}
-->
</canvas>
</section>

<section>
<h2>Parallel Scaling Performance</h2>
<small>OpenTimer v2 (Taskflow) Runtime across Increasing Numbers of Cores</small>
<canvas class="stretch" data-chart="bar">
<!--
{
  "data" : {
    "labels": ["1 core", "2 cores", "3 cores", "4 cores"],
    "datasets": [{
      "label": "cpu runtime (ms)",
      "data": [57, 34, 29, 23]
    }]
  },
  "options": {
    "tooltips": {"mode": "label"},
    "responsive": true,
    "scales": {
      "xAxes": [{
        "stacked": false
      }],
      "yAxes": [{
        "position": "left",
        "id": "y-axis-0"
      }]
    }
  }
}
-->
</canvas>
</section>


<section>
<h2>Dynamic Tasking</h2>
<pre><code class="language-cpp stretch" contenteditable=true>tf::Taskflow tf;
auto A = tf.emplace([](){}).name("A");
auto C = tf.emplace([](){}).name("C");
auto D = tf.emplace([](){}).name("D");

auto B = tf.emplace([] (auto&amp; subflow) {
  auto B0 = subflow.emplace([](){}).name("B0");
  auto B1 = subflow.emplace([](){}).name("B1");
  auto B2 = subflow.emplace([](){}).name("B2");
  auto B3 = subflow.emplace([](){}).name("B3");
  auto B4 = subflow.emplace([](){}).name("B4");
  B0.precede(B1, B2, B3);
  B4.succeed(B1, B2, B3);
}).name("B");
            
A.precede(B);  // B runs after A 
A.precede(C);  // C runs after A 
B.precede(D);  // D runs after B 
C.precede(D);  // D runs after C 
</code></pre>
<span class="fragment current-only" data-code-focus="6"></span>
<span class="fragment current-only" data-code-focus=""></span>
</section>

<section>
<!--img src="image/dynamic_tasking.png" style="background:none"-->
<img src="image/dynamic-tasking.svg" style="background:none">
</section>


<section>
<h2>Conditional Tasking</h2>
<pre><code class="language-cpp stretch" contenteditable=true>tf::Taskflow tf;
auto A = tf.emplace([](){}).name("A");
auto B = tf.emplace([](){}).name("B");
auto C = tf.emplace([](){}).name("C");
auto D = tf.emplace([](){}).name("D");
auto E = tf.emplace([](){ return rand()%3; }).name("E");
auto F = tf.emplace([](){}).name("F");

A.precede(B, C);  // A runs before B and C
B.precede(D);     // B runs before D
C.precede(F);     // C runs before F
D.precede(B);     // D conditions B on 0 (feedback)
D.precede(D);     // D conditions D on 1 (self-loop)
D.precede(E);     // D conditions E on 2
</code></pre>
<span class="fragment current-only" data-code-focus="6,12-14"></span>
<span class="fragment current-only" data-code-focus=""></span>
</section>

<section>
<img src="image/conditional-tasking.svg" style="background:none">
</section>

<section>
<h2>Composability</h2>

<pre><code class="language-cpp stretch" contenteditable=true>tf::Taskflow A, B;
auto [taskA1, taskA2, taskA3] = A.emplace(
  []() { std::cout &lt;&lt; "Task A1\n"; },
  []() { std::cout &lt;&lt; "Task A2\n"; },
  []() { std::cout &lt;&lt; "Task A3\n"; }
);
taskA1.precede(taskA2, taskA3);

auto [taskB1, taskB2, taskB3] = B.emplace(
  []() { std::cout &lt;&lt; "Task B1\n"; },
  []() { std::cout &lt;&lt; "Task B2\n"; },
  []() { std::cout &lt;&lt; "Task B3\n"; }
);
// Compose taskflow B
auto module_A = B.composed_of(A); 
taskB1.precede(module_A);
module_A.precede(taskB2, taskB3);
</code></pre>
<span class="fragment current-only" data-code-focus="16"></span>
</section>


<section>
<img src="image/composable-tasking.svg" style="background:none">
</section>

<section>
<h2>Concurrent CPU-GPU Tasking</h2>

<pre><code class="language-cpp stretch" contenteditable=true>tf::Taskflow taskflow;
tf::Executor executor;
auto allocate_x = taskflow.emplace(
  [&](){ cudaMalloc(&dx, N*sizeof(float));}
);
auto allocate_y = taskflow.emplace(
  [&](){ cudaMalloc(&dy, N*sizeof(float));}
);
auto cudaflow = taskflow.emplace([&](tf::cudaFlow& cf) {
  auto h2d_x = cf.copy(dx, hx.data(), N);
  auto h2d_y = cf.copy(dy, hy.data(), N);
  auto d2h_x = cf.copy(hx.data(), dx, N);
  auto d2h_y = cf.copy(hy.data(), dy, N);
  auto op = cf.kernel(N/256, 256, 0, saxpy, N, 2, dx, dy);
  op.succeed(h2d_x, h2d_y).precede(d2h_x, d2h_y);
});
cudaflow.succeed(allocate_x, allocate_y);
executor.run(taskflow).wait();
</code></pre>
<span class="fragment current-only" data-code-focus="9-16"></span>
</section>


<section>
<img src="image/cudaFlow.svg" style="background:none">
</section>


<section>
<h2>Monitor Thread Activities</h2>
<pre><code class="language-cpp stretch" contenteditable=true style="width: 900px">tf::Taskflow taskflow;
auto observer = executor.make_observer&lt;tf::ExecutorObserver&gt;();

auto [taskA1, taskA2, taskA3] = taskflow.emplace(
  []() { std::cout &lt;&lt; "Task A1\n"; },
  []() { std::cout &lt;&lt; "Task A2\n"; },
  []() { std::cout &lt;&lt; "Task A3\n"; }
);
taskA1.precede(taskA2, taskA3);

taskflow.run_n(A, 10).get();

// Dump thread activities to chrome://tracing
observer.dump(std::cout);
</code></pre>
<span class="fragment current-only" data-code-focus="2,14"></span>
</section>

<section>
<h2>chrome://tracing</h2>
<img data-src="image/timeline.png", style="max-height: 80%">
</section>


<section>
<h2>Drop-in Integration</h2>
<pre><code class="language-bash stretch" contenteditable=true># clone the newest Taskflow
~$ git clone https://github.com/taskflow/taskflow.git

# Taskflow is header-only
~$ cp -r taskflow/taskflow my_project/

# compile you code with g++, clang++, or msvc
~$ g++ -std=c++17 my_project/test.cpp -pthread
</code></pre>
<span class="fragment current-only" data-code-focus="4,5"></span>
</section>

<section>
<h2>We â™¥ Feedback</h2>
<p><q>Taskflow is the cleanest Task API I've ever seen.</q></p>
<p><q>Taskflow has a very simple and elegant tasking interface. The performance also scales very well.</q></p>
<p><q>Best Poster Award in the official CPP Conference, 2018</q></p>
<p><q>Second Prize of Open Source Software Competition in ACM Multimedia Conference, 2019</q></p>
</section>


<section>
<h2>Acknowledgment</h2>
<ul>
  <li>Development Team</li>
  <li>Contributors</li>
  <li>Sponsors (NSF, DARPA)</li>
  <li>... and all users!</li>
</ul>
</section>

        
<section data-markdown>
  <script type="text/template">
# Thank You

| Without Taskflow | With Taskflow |
| :------------------: | :---------------: |
| ![](image/profile_without_taskflow.gif) | ![](image/profile_with_taskflow.gif) |

<p><i class="fa fa-github"></i><a href="https://github.com/taskflow/taskflow">Project GitHub</a></p>
<p><i class="fa fa-book"></i><a href="https://taskflow.github.io/taskflow/index.html">API Documentation</a></p>
  </script>
</section>

      </div>
    </div>


    <script src="lib/js/head.min.js"></script>
    <script src="js/reveal.js"></script>

    <script>

      // More info https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        controls: true,
        progress: true,
        history: true,
        center: true,

        transition: 'slide', // none/fade/slide/convex/concave/zoom

        chart: {
          defaults: { 
            global: { 
              title: { fontColor: "#FFF" }, 
              legend: {
                labels: { fontColor: "#FFF" },
              },
            },
            scale: { 
              scaleLabel: { fontColor: "#FFF" }, 
              gridLines: { color: "#FFF", zeroLineColor: "#FFF" }, 
              ticks: { fontColor: "#FFF" }, 
            } 
          },
          line: { borderColor: [ "rgba(20,220,220,.8)" , "rgba(220,120,120,.8)", "rgba(20,120,220,.8)" ]}, 
          bar: { backgroundColor: [ "rgba(20,220,220,.8)" , "rgba(220,120,120,.8)", "rgba(20,120,220,.8)" ]}, 
          pie: { backgroundColor: [ ["rgba(0,0,0,.8)" , "rgba(220,20,20,.8)", "rgba(20,220,20,.8)", "rgba(220,220,20,.8)", "rgba(20,20,220,.8)"] ]},
          radar: { borderColor: [ "rgba(20,220,220,.8)" , "rgba(220,120,120,.8)", "rgba(20,120,220,.8)" ]}, 
        },

        // Chart attributes
        dependencies: [
          { src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
          { src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
          { src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
          { src: 'plugin/highlight/highlight.js' },
          { src: 'plugin/search/search.js', async: true },
          { src: 'plugin/zoom-js/zoom.js', async: true },
          { src: 'plugin/notes/notes.js', async: true },
          { src: 'plugin/line-numbers/line-numbers.js' },
          { src: 'plugin/code-focus/reveal-code-focus.js', async: true, callback: function() { RevealCodeFocus(); } },
          { src: 'plugin/chart/Chart.min.js' },       
          { src: 'plugin/chart/csv2chart.js', async: false }
        ]
      });
    </script>

  </body>
</html>
